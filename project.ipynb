{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f313b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3929 image/mask pairs.\n",
      "\n",
      "Image: /home/tyler/projects/UNet/data/lgg-mri-segmentation/kaggle_3m/TCGA_DU_8164_19970111/TCGA_DU_8164_19970111_1.tif\n",
      "Mask: /home/tyler/projects/UNet/data/lgg-mri-segmentation/kaggle_3m/TCGA_DU_8164_19970111/TCGA_DU_8164_19970111_1_mask.tif\n",
      "Image shape: (256, 256, 3)\n",
      "Mask shape: (256, 256)\n",
      "Tumor images: 1373\n",
      "No-tumor images: 2556\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def load_dataset(root_dir):\n",
    "    \"\"\"\n",
    "    Recursively parse the LGG MRI dataset.\n",
    "    Returns a list of dictionaries:\n",
    "    [\n",
    "      {\n",
    "        \"image_path\": \"...\",\n",
    "        \"mask_path\": \"...\",\n",
    "        \"image\": np.ndarray,\n",
    "        \"mask\": np.ndarray\n",
    "      },\n",
    "      ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Walk through all subdirectories\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        # Only consider tif files\n",
    "        tifs = [f for f in files if f.endswith(\".tif\")]\n",
    "\n",
    "        # Create mapping: index -> file\n",
    "        image_files = {f.replace(\"_mask\", \"\"): f for f in tifs if \"_mask\" not in f}\n",
    "        mask_files  = {f.replace(\"_mask\", \"\"): f for f in tifs if \"_mask\" in f}\n",
    "\n",
    "        # Pair image + mask files\n",
    "        for key in sorted(image_files.keys()):\n",
    "            if key in mask_files:\n",
    "                img_path = os.path.join(subdir, image_files[key])\n",
    "                mask_path = os.path.join(subdir, mask_files[key])\n",
    "\n",
    "                # Load arrays\n",
    "                img = np.array(Image.open(img_path))\n",
    "                mask = np.array(Image.open(mask_path))\n",
    "\n",
    "                data.append({\n",
    "                    \"image_path\": img_path,\n",
    "                    \"mask_path\": mask_path,\n",
    "                    \"image\": img,\n",
    "                    \"mask\": mask\n",
    "                })\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = \"/home/tyler/projects/UNet/data/lgg-mri-segmentation/kaggle_3m\"\n",
    "    dataset = load_dataset(root)\n",
    "\n",
    "    print(f\"Loaded {len(dataset)} image/mask pairs.\\n\")\n",
    "\n",
    "    # Example: print one sample\n",
    "    sample = dataset[0]\n",
    "    print(\"Image:\", sample[\"image_path\"])\n",
    "    print(\"Mask:\", sample[\"mask_path\"])\n",
    "    print(\"Image shape:\", sample[\"image\"].shape)\n",
    "    print(\"Mask shape:\", sample[\"mask\"].shape)\n",
    "\n",
    "    # ---- Split into tumor / non-tumor ----\n",
    "    tumor = []\n",
    "    no_tumor = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        if np.any(item[\"mask\"] > 0):\n",
    "            tumor.append(item)\n",
    "        else:\n",
    "            no_tumor.append(item)\n",
    "    \n",
    "    print(\"Tumor images:\", len(tumor))\n",
    "    print(\"No-tumor images:\", len(no_tumor))\n",
    "    \n",
    "    images = np.stack([\n",
    "        np.transpose(item[\"image\"], (2, 0, 1))  # (H,W,C) â†’ (C,H,W)\n",
    "        for item in dataset\n",
    "    ]).astype(np.float32)                        # final shape [N, 3, 256, 256]\n",
    "\n",
    "    masks = np.stack([\n",
    "        item[\"mask\"]                             # (H,W)\n",
    "        for item in dataset\n",
    "    ]).astype(np.float32)                        # final shape [N, 256, 256]\n",
    "    images = np.ascontiguousarray(images)\n",
    "    masks = np.ascontiguousarray(masks)\n",
    "    N, C, H, W = images.shape\n",
    "    shape = [float(N), float(C), float(H), float(W)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "676463b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3929\n",
      "255.0\n"
     ]
    }
   ],
   "source": [
    "print(N)\n",
    "for i in range(3929):\n",
    "    if(masks[i][125][125] != 0):\n",
    "        print(masks[i][125][125])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8007f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3929, 3, 256, 256)\n",
      "(3929, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d2b26d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 196\n",
      "Test images: 3733\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split 80% train / 20% test\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(\n",
    "    images, masks, test_size=0.95, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Train images: {train_images.shape[0]}\")\n",
    "print(f\"Test images: {test_images.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ffaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 3, 256, 256)\n",
      "(196, 256, 256)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c173f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_net import NeuralNet\n",
    "from neural_net import LayerType\n",
    "from neural_net import LayerDesc\n",
    "from neural_net import ActivationType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df61e54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing NN\n",
      "CUDA device reset.\n"
     ]
    }
   ],
   "source": [
    "UNET = NeuralNet()  # instantiate the C++ class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a6fbce",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# assume strides and sizes tile image correctly without padding\n",
    "max_pool_stride = 2\n",
    "max_pool_size = 2\n",
    "H1 = 256\n",
    "H2 = int(H1 / max_pool_stride)\n",
    "H3 = int(H2 / max_pool_stride)\n",
    "H4 = int(H3 / max_pool_stride)\n",
    "\n",
    "W1 = 256\n",
    "W2 = int(W1 / max_pool_stride)\n",
    "W3 = int(W2 / max_pool_stride)\n",
    "W4 = int(W3 / max_pool_stride)\n",
    "in_channels = 3\n",
    "F1 = 64\n",
    "F2 = int(2 * F1)\n",
    "F3 = int(2 * F2)\n",
    "F4 = int(2 * F3)\n",
    "\n",
    "# keep encoder and decoder even\n",
    "upsample_factor = max_pool_stride\n",
    "\n",
    "UNET.create(\n",
    "    [\n",
    "        # parameters are in_height, in_width, in_channels, out_channels, kernel size, padding, and stride\n",
    "        LayerDesc(LayerType.CONV_LAYER, [H1, W1, in_channels, F1, 3, 1, 1], []),  # 0\n",
    "        # parameters are in_channels, in_height, in_width, size and stride\n",
    "        LayerDesc(\n",
    "            LayerType.MAX_POOL_LAYER, [F1, H1, W1, max_pool_size, max_pool_stride], [0]\n",
    "        ),  # 1\n",
    "        LayerDesc(LayerType.CONV_LAYER, [H2, W2, F1, F2, 3, 1, 1], [1]),  # 2\n",
    "        LayerDesc(\n",
    "            LayerType.MAX_POOL_LAYER, [F2, H2, W2, max_pool_size, max_pool_stride], [2]\n",
    "        ),  # 3\n",
    "        LayerDesc(LayerType.CONV_LAYER, [H3, W3, F2, F3, 3, 1, 1], [3]),  # 4\n",
    "        LayerDesc(\n",
    "            LayerType.MAX_POOL_LAYER, [F3, H3, W3, max_pool_size, max_pool_stride], [4]\n",
    "        ),  # 5\n",
    "        LayerDesc(LayerType.CONV_LAYER, [H4, W4, F3, F4, 3, 1, 1], [5]),  # 6\n",
    "        # parameters are h_in, w_in, c_in, c_out, stride/upscale\n",
    "        LayerDesc(\n",
    "            LayerType.UPSAMPLING_LAYER, [H4, W4, F4, F3, upsample_factor], [6]\n",
    "        ),  # 7\n",
    "        # parameters are fully determined by parents. First parent is skip connection, second is convolution below\n",
    "        LayerDesc(LayerType.ATTENTION_LAYER, [], [4, 6]),  # 8\n",
    "        # parameters are fully determined by parents. First parent is from skip/attention, second is from convolution below\n",
    "        LayerDesc(LayerType.CONCAT_LAYER, [], [8, 7]),  # 9\n",
    "        LayerDesc(LayerType.CONV_LAYER, [H3, W3, F3, F2, 3, 1, 1], [9]),  # 10\n",
    "        LayerDesc(\n",
    "            LayerType.UPSAMPLING_LAYER, [H3, W3, F2, F2, upsample_factor], [10]\n",
    "        ),  # 11\n",
    "        LayerDesc(LayerType.ATTENTION_LAYER, [], [2, 10]),  # 12\n",
    "        LayerDesc(LayerType.CONCAT_LAYER, [], [12, 11]),  # 13\n",
    "        LayerDesc(LayerType.CONV_LAYER, [H2, W2, F3, F1, 3, 1, 1], [13]),  # 14\n",
    "        LayerDesc(\n",
    "            LayerType.UPSAMPLING_LAYER, [H2, W2, F1, F1, upsample_factor], [14]\n",
    "        ),  # 15\n",
    "        LayerDesc(LayerType.ATTENTION_LAYER, [], [0, 14]),  # 16\n",
    "        LayerDesc(LayerType.CONCAT_LAYER, [], [16, 15]),  # 17\n",
    "        LayerDesc(LayerType.CONV_LAYER, [H1, W1, F2, 1, 3, 1, 1], [17], ActivationType.SIGMOID),  # 18\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "UNET.train(train_images, train_masks, learning_rate, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a997b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "3\n",
      "245.5625\n"
     ]
    }
   ],
   "source": [
    "print(dataset[2][\"image\"].shape)\n",
    "print(dataset[2][\"image\"][40][30][1])\n",
    "print(len(dataset)/16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee3ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
